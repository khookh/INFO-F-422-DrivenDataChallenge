{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This section aims to assess and compare the performances of the models implemented in the sections 4.1, 4.2 and 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-14\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "\n",
      "Attaching package: ‘ggplot2’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:randomForest’:\n",
      "\n",
      "    margin\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(randomForest)\n",
    "library(caret)\n",
    "library(e1071)\n",
    "validation_set <- read.csv(\"../Data/PreProcess/processed_verification_data_split.csv\") # load validation set\n",
    "column_to_drop<-c(\"X.1\",\"X\")\n",
    "# Dropped \"X.1\",\"X\" because they just represent the row numbers\n",
    "validation_set<-validation_set[,!(names(validation_set) %in% column_to_drop)] # drop the desired columns on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(predvars, data, env): objet 'colored' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(predvars, data, env): objet 'colored' introuvable\nTraceback:\n",
      "1. predict(classifierRF, validation_set)",
      "2. predict.randomForest(classifierRF, validation_set)",
      "3. model.frame(Terms, newdata, na.action = na.omit)",
      "4. model.frame.default(Terms, newdata, na.action = na.omit)",
      "5. eval(predvars, data, env)",
      "6. eval(predvars, data, env)"
     ]
    }
   ],
   "source": [
    "load(\"4-Models/random_forest.RData\") # load Random Forest trained model -> name : classifierRF\n",
    "pred <- predict(classifierRF,validation_set) # Random Forest model prediction on validation set\n",
    "\n",
    "#table(observed=validation_set$id,predicted=pred) # Random Forest Confusion Matrix on validation set\n",
    "cmRF <- confusionMatrix(data=pred, reference = factor(validation_set$id)) # Random Forest Confusion Matrix on validation set\n",
    "\n",
    "\n",
    "kpRF <- cmRF$overall[\"Kappa\"] # Cohen's Kappa coefficient, allows to indicate the level of agreement between prediction and expected\n",
    "                          # Allows to take into account the proportion of false negative https://thenewstack.io/cohens-kappa-what-it-is-when-to-use-it-and-how-to-avoid-its-pitfalls/\n",
    "acRF <- cmRF$overall[\"Accuracy\"] # Accuracy (CM diagonal)\n",
    "\n",
    "cmRF$table # Confusion Matrix displayed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine performance and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"4-Models/svm_poly_classifier.RData\") # loads SVM classifier -> name: svm_model_poly\n",
    "\n",
    "pred <- predict(svm_model_poly, validation_set, probability=TRUE) # SVM prediction on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         Reference\n",
       "Prediction                functional functional needs repair non functional\n",
       "  functional                    5560                     709           2191\n",
       "  functional needs repair         29                      29             24\n",
       "  non functional                 934                     179           2455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Accuracy:</strong> 0.664244426094137"
      ],
      "text/latex": [
       "\\textbf{Accuracy:} 0.664244426094137"
      ],
      "text/markdown": [
       "**Accuracy:** 0.664244426094137"
      ],
      "text/plain": [
       " Accuracy \n",
       "0.6642444 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Kappa:</strong> 0.341102446379934"
      ],
      "text/latex": [
       "\\textbf{Kappa:} 0.341102446379934"
      ],
      "text/markdown": [
       "**Kappa:** 0.341102446379934"
      ],
      "text/plain": [
       "    Kappa \n",
       "0.3411024 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmSVM <- confusionMatrix(data=pred, reference=factor(validation_set$id[-1]))\n",
    "\n",
    "kpSVM <- cmSVM$overall[\"Kappa\"] \n",
    "\n",
    "acSVM <- cmSVM$overall[\"Accuracy\"]\n",
    "\n",
    "cmSVM$table\n",
    "acSVM\n",
    "kpSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 66% of accuracy for the SVM classification. There are issues with the \"functional needs repair\" class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set <- read.csv(\"../Data/PreProcess/processed_training_data_split.csv\")\n",
    "column_to_drop<-c(\"X.1\",\"X\")\n",
    "training_set<-training_set[,!(names(training_set) %in% column_to_drop)] # drop the desired columns\n",
    "training_set$id <- factor(training_set$id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters obtained so far\n",
    "tuned <- tune.svm(id~., data = training_set, kernel=\"polynomial\", cost=10, scale=FALSE, probability=TRUE, tunecontrol=tune.control(cross=10))\n",
    "summary(tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
